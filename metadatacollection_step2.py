# -*- coding: utf-8 -*-
"""MetadataCollection_Step2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yw20p3-P2VuMdpV5E55quyABdlha5s98
"""

pip install GDAL

"""### 1 Check Shapefile"""

from google.colab import drive
drive.mount('/content/drive/')

import geopandas as gpd

# Load your shapefile
shapefile_path = 'your_path'  # Replace with the path to your shapefile
gdf = gpd.read_file(shapefile_path)

# Print the first few rows of the DataFrame to inspect the data
print(gdf.head())

# Check for duplicate points
duplicates = gdf[gdf.duplicated(subset=['geometry'])]
print(f"Number of duplicate points: {len(duplicates)}")

# If you want to see the duplicate points
if len(duplicates) > 0:
    print(duplicates)

# Summary of the data
print("\nSummary of the data:")
print(gdf.describe())

# Check the number of unique points
unique_points = gdf['geometry'].unique()
print(f"Number of unique points: {len(unique_points)}")

"""### 2 Remove duplicate points"""

# Remove duplicate points based on geometry
gdf_unique = gdf.drop_duplicates(subset=['geometry'])

# Save the unique points to a new shapefile
unique_shapefile_path = 'newshp_path'  # Replace with your desired path
gdf_unique.to_file(unique_shapefile_path)

print(f"Original number of points: {len(gdf)}")
print(f"Number of unique points after removing duplicates: {len(gdf_unique)}")

"""### 3 GSV Metadata Collection"""

import requests
import geopandas as gpd

def get_session_token(api_key):
    session_url = "https://tile.googleapis.com/v1/createSession"
    headers = {'Content-Type': 'application/json'}
    params = {'key': api_key}
    body = {
        "mapType": "streetview",
        "language": "en-US",
        "region": "US"
    }

    response = requests.post(session_url, headers=headers, json=body, params=params)
    response.raise_for_status()  # This will raise an exception for HTTP errors

    json_response = response.json()
    if 'session' in json_response:
        return json_response['session']
    else:
        raise ValueError("JSON response does not contain 'session'")

# Use your actual API key here
api_key = 'your_key'
session_token = get_session_token(api_key)
print(session_token)  # This should now print the correct session token


def get_pano_id(lat, lng, session_token, api_key):
    pano_url = "https://tile.googleapis.com/v1/streetview/panoIds"
    headers = {'Content-Type': 'application/json'}
    params = {
        'session': session_token,
        'key': api_key
    }
    body = {
        "locations": [{"lat": lat, "lng": lng}],
        "radius": 20
    }
    response = requests.post(pano_url, headers=headers, json=body, params=params)
    response.raise_for_status()
    pano_ids = response.json().get('panoIds')
    return pano_ids[0] if pano_ids else None

def get_pano_metadata(pano_id, session_token, api_key):
    metadata_url = f"https://tile.googleapis.com/v1/streetview/metadata"
    params = {
        'session': session_token,
        'key': api_key,
        'panoId': pano_id
    }
    response = requests.get(metadata_url, params=params)
    response.raise_for_status()
    return response.json()

# Load your shapefile
shapefile_path = 'your_path'  # Replace with your actual shapefile path
gdf = gpd.read_file(shapefile_path)

import requests

output_dir = 'your_path'  # Specify the directory where you want to save the files
file_count = 1  # Initialize the file counter

for index, row in gdf.iterrows():
    lat = row.geometry.y
    lng = row.geometry.x
    pano_id = get_pano_id(lat, lng, session_token, api_key)

    if pano_id:
        try:
            metadata = get_pano_metadata(pano_id, session_token, api_key)
            if index % 1000 == 0:
                # Create a new file every 1000 rows
                output_file_path = f'{output_dir}SFDT_Metadata{file_count}.txt'
                with open(output_file_path, 'w') as file:
                    file.write('panoID, panoDate, latitude, longitude, tilt\n')  # Write header
                file_count += 1
            with open(output_file_path, 'a') as file:
                file.write(f"{metadata['panoId']}, {metadata['date']}, {metadata['lat']}, {metadata['lng']}, {metadata['tilt']}\n")
        except requests.exceptions.HTTPError as e:
            if e.response.status_code == 404:
                print(f"HTTP Error 404: No panorama found for location at index {index}")
            else:
                print(f"HTTP Error {e.response.status_code} occurred for location at index {index}")
    else:
        print(f"No panorama found for location at index {index}")

print("Metadata collection complete.")

"""### 4 Convert Format"""

import os

# Define the directory where the original files are located
input_dir = 'shp_path'

# Define the directory where the converted files will be saved
output_dir = 'Metadata_path'

# Ensure the output directory exists
os.makedirs(output_dir, exist_ok=True)

# Iterate over all files in the input directory
for filename in os.listdir(input_dir):
    if filename.endswith('.txt'):
        input_file_path = os.path.join(input_dir, filename)
        output_file_path = os.path.join(output_dir, filename)

        # Read the input file and write to the output file with the desired format
        with open(input_file_path, 'r') as infile, open(output_file_path, 'w') as outfile:
            # Skip the header from the input file
            infile.readline()  # skip header line

            # Enumerate over each line in the input file, starting with index 1
            for idx, line in enumerate(infile, start=1):
                # Split the line into components assuming it's comma-separated
                components = line.strip().split(', ')

                # Reorder and format the components to match the desired output format
                pano_id, pano_date, latitude, longitude, tilt = components
                formatted_line = f"panoID: {pano_id} panoDate: {pano_date} latitude: {latitude} longitude: {longitude} tilt: {tilt}\n"

                # Write the formatted line to the output file
                outfile.write(formatted_line)

        print(f"Conversion complete. Formatted metadata saved to: {output_file_path}")

