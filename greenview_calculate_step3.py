# -*- coding: utf-8 -*-
"""GreenView_Calculate_Step3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QFvLhjrChxPn4Ql7n70seHBXIgBG-pIL
"""

# This program is used to calculate the green view index based on the collecte metadata. The
# Object based images classification algorithm is used to classify the greenery from the GSV imgs
# in this code, the meanshift algorithm implemented by pymeanshift was used to segment image
# first, based on the segmented image, we further use the Otsu's method to find threshold from
# ExG image to extract the greenery pixels.

# For more details about the object based image classification algorithm
# check: Li et al., 2016, Who lives in greener neighborhoods? the distribution of street greenery and it association with residents' socioeconomic conditions in Hartford, Connectictu, USA

# This program implementing OTSU algorithm to chose the threshold automatically
# For more details about the OTSU algorithm and python implmentation
# cite: http://docs.opencv.org/trunk/doc/py_tutorials/py_imgproc/py_thresholding/py_thresholding.html


# Copyright(C) Xiaojiang Li, Ian Seiferling, Marwa Abdulhai, Senseable City Lab, MIT
# First version June 18, 2014

# This version is adjusted by Lulu Liu, UCB (12/2023)

pip install pymeanshift

import pymeanshift as pms
import numpy as np
import requests
import geopandas as gpd
import csv
import os
import numpy as np
import requests
from PIL import Image
from io import BytesIO

def graythresh(array,level):
    '''array: is the numpy array waiting for processing
    return thresh: is the result got by OTSU algorithm
    if the threshold is less than level, then set the level as the threshold
    by Xiaojiang Li
    '''

    import numpy as np

    maxVal = np.max(array)
    minVal = np.min(array)

#   if the inputImage is a float of double dataset then we transform the data
#   in to byte and range from [0 255]
    if maxVal <= 1:
        array = array*255
        # print "New max value is %s" %(np.max(array))
    elif maxVal >= 256:
        array = np.int((array - minVal)/(maxVal - minVal))
        # print "New min value is %s" %(np.min(array))

    # turn the negative to natural number
    negIdx = np.where(array < 0)
    array[negIdx] = 0

    # calculate the hist of 'array'
    dims = np.shape(array)
    hist = np.histogram(array,range(257))
    P_hist = hist[0]*1.0/np.sum(hist[0])

    omega = P_hist.cumsum()

    temp = np.arange(256)
    mu = P_hist*(temp+1)
    mu = mu.cumsum()

    n = len(mu)
    mu_t = mu[n-1]

    sigma_b_squared = (mu_t*omega - mu)**2/(omega*(1-omega))

    # try to found if all sigma_b squrered are NaN or Infinity
    indInf = np.where(sigma_b_squared == np.inf)

    CIN = 0
    if len(indInf[0])>0:
        CIN = len(indInf[0])

    maxval = np.max(sigma_b_squared)

    IsAllInf = CIN == 256
    if IsAllInf !=1:
        index = np.where(sigma_b_squared==maxval)
        idx = np.mean(index)
        threshold = (idx - 1)/255.0
    else:
        threshold = level

    if np.isnan(threshold):
        threshold = level

    return threshold

def VegetationClassification(Img):
    '''
    This function is used to classify the green vegetation from GSV image,
    This is based on object based and otsu automatically thresholding method
    The season of GSV images were also considered in this function
        Img: the numpy array image, eg. Img = np.array(Image.open(StringIO(response.content)))
        return the percentage of the green vegetation pixels in the GSV image

    By Xiaojiang Li
    '''

    import pymeanshift as pms
    import numpy as np

    # use the meanshift segmentation algorithm to segment the original GSV image
    (segmented_image, labels_image, number_regions) = pms.segment(Img,spatial_radius=6,
                                                     range_radius=7, min_density=40)

    I = segmented_image/255.0

    red = I[:,:,0]
    green = I[:,:,1]
    blue = I[:,:,2]

    # calculate the difference between green band with other two bands
    green_red_Diff = green - red
    green_blue_Diff = green - blue

    ExG = green_red_Diff + green_blue_Diff
    diffImg = green_red_Diff*green_blue_Diff

    redThreImgU = red < 0.6
    greenThreImgU = green < 0.9
    blueThreImgU = blue < 0.6

    shadowRedU = red < 0.3
    shadowGreenU = green < 0.3
    shadowBlueU = blue < 0.3
    del red, blue, green, I

    greenImg1 = redThreImgU * blueThreImgU*greenThreImgU
    greenImgShadow1 = shadowRedU*shadowGreenU*shadowBlueU
    del redThreImgU, greenThreImgU, blueThreImgU
    del shadowRedU, shadowGreenU, shadowBlueU

    greenImg3 = diffImg > 0.0
    greenImg4 = green_red_Diff > 0
    threshold = graythresh(ExG, 0.1)

    if threshold > 0.1:
        threshold = 0.1
    elif threshold < 0.05:
        threshold = 0.05

    greenImg2 = ExG > threshold
    greenImgShadow2 = ExG > 0.05
    greenImg = greenImg1*greenImg2 + greenImgShadow2*greenImgShadow1
    del ExG,green_blue_Diff,green_red_Diff
    del greenImgShadow1,greenImgShadow2

    # calculate the percentage of the green vegetation
    greenPxlNum = len(np.where(greenImg != 0)[0])
    greenPercent = greenPxlNum/(200*200)*100
    del greenImg1,greenImg2
    del greenImg3,greenImg4

    return greenPercent

def get_session_token(api_key):
    session_url = "https://tile.googleapis.com/v1/createSession"
    headers = {'Content-Type': 'application/json'}
    params = {'key': api_key}
    body = {
        "mapType": "streetview",
        "language": "en-US",
        "region": "US"
    }

    response = requests.post(session_url, headers=headers, json=body, params=params)
    response.raise_for_status()  # This will raise an exception for HTTP errors

    json_response = response.json()
    if 'session' in json_response:
        return json_response['session']
    else:
        raise ValueError("JSON response does not contain 'session'")

# Use your actual API key here
api_key = 'your_Key'
session_token = get_session_token(api_key)
print(session_token)

def calculate_gvi_and_save_to_csv(txt_file, key_file, session_token, output_csv,non_winter_months):
    """
    This function calculates the Green View Index (GVI) for the first 50 panorama IDs in the given text file
    and saves the results in a CSV file, with print statements to show progress.
    """
    headingArr = 360 / 6 * np.array([0, 1, 2, 3, 4, 5])
    numGSVImg = len(headingArr)
    # Read API keys
    with open(key_file, "r") as kf:
        keylist = [key.strip() for key in kf.readlines()]

    # Set up the CSV file for writing
    with open(output_csv, 'w', newline='') as csvfile:
        csvwriter = csv.writer(csvfile)
        csvwriter.writerow(['GreenView', 'PanoID', 'Latitude', 'Longitude'])

        zoom_level = 2
        tile_x, tile_y = 0, 1

        # Read the panorama IDs from the text file
        with open(txt_file, "r") as f:
          for line in f:
            parts = line.split()
            panoID = parts[1]
            panoDate = parts[3]
            month = panoDate.split('-')[1]

            if month not in non_winter_months:
              continue

            lat = parts[5]
            lon = parts[7]
            greenPercentList = []

             # Fetch images and calculate GVI for each heading
            for i, heading in enumerate(headingArr):
                 key = keylist[i % len(keylist)]
                 URL = f"https://tile.googleapis.com/v1/streetview/thumbnail?session={session_token}&key={key}&panoId={panoID}&height=200&width=200&yaw={heading}"
                 try:
                     response = requests.get(URL)
                     if response.status_code == 200:
                         im = np.array(Image.open(BytesIO(response.content)))
                         greenPercent = VegetationClassification(im)
                         if greenPercent >= 0:  # Assuming negative values indicate errors
                              greenPercentList.append(greenPercent)
                     else:
                         print(f"Error fetching image for panoID {panoID}: HTTP {response.status_code}")
                         greenPercentTotal = -1000
                         break
                 except requests.RequestException as e:
                    print(f"Request failed for panoID {panoID}: {e}")
                    greenPercentTotal = -1000
                    break
            greenPercentList = [gp for gp in greenPercentList if gp >= 0]
            greenPercentList.sort(reverse=True)

            # Calculate the average GVI
            # Take the average of the 4 largest values
            if len(greenPercentList) >= 4:
              gvi = sum(greenPercentList[:4]) / 4
            else:
              gvi = None

            # Print the current panoID and its GVI to the console
            print(f'Calculating GVI for panoID: {panoID}, GVI: {gvi}, Lat: {lat}, Lon: {lon}')  # Print statement added here

            # Write the result to the CSV file
            csvwriter.writerow([gvi, panoID, lat, lon])

from google.colab import drive
drive.mount('/content/drive/')

txt_file='txtfile_in_metadata'
key_file='keyfile'
output_csv = 'output_path'
non_winter_months = ['03','04', '05', '06', '07', '08', '09','10','11']
calculate_gvi_and_save_to_csv(txt_file, key_file, session_token,output_csv,non_winter_months)

key_file='/content/drive/MyDrive/C257 Project/Data/Keyfile.txt'
with open(key_file, "r") as kf:
     keylist = [key.strip() for key in kf.readlines()]

keylist

